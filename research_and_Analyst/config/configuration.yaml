
llm:
  groq:
    provider: "groq"
    model_name: "deepseek-r1-distill-llama-70b"
    temperature: 0
    max_output_tokens: 2048

  google:
    provider: "google"
    model_name: "gemini-3-flash-preview"
    temperature: 0
    max_output_tokens: 2048

  openai:
     provider: "openai"
     model_name: "gpt-4o"
     temperature: 0
     